{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "# Created by: BoyuanJiang\n",
    "# College of Information Science & Electronic Engineering,ZheJiang University\n",
    "# Email: ginger188@gmail.com\n",
    "# Copyright (c) 2017\n",
    "\n",
    "# @Time    :17-8-29 22:26\n",
    "# @FILE    :mainOmniglot.py\n",
    "# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "\n",
    "from data_loader import TreeBankDataset\n",
    "from OmniglotBuilder import OmniglotBuilder\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(sequences, batch_first=False, padding_value=0):\n",
    "\n",
    "\n",
    "    # assuming trailing dimensions and type of all the Variables\n",
    "    # in sequences are same and fetching those from sequences[0]\n",
    "    max_size = sequences[0].size()\n",
    "    max_len, trailing_dims = max_size[0], max_size[1:]\n",
    "    prev_l = max_len\n",
    "    if batch_first:\n",
    "        out_dims = (len(sequences), max_len) + trailing_dims\n",
    "    else:\n",
    "        out_dims = (max_len, len(sequences)) + trailing_dims\n",
    "\n",
    "    out_variable = Variable(sequences[0].data.new(*out_dims).fill_(padding_value))\n",
    "    for i, variable in enumerate(sequences):\n",
    "        length = variable.size(0)\n",
    "        # temporary sort check, can be removed when we handle sorting internally\n",
    "        if prev_l < length:\n",
    "            raise ValueError(\"lengths array has to be sorted in decreasing order\")\n",
    "        prev_l = length\n",
    "        # use index notation to prevent duplicate references to the variable\n",
    "        if batch_first:\n",
    "            out_variable[i, :length, ...] = variable\n",
    "        else:\n",
    "            out_variable[:length, i, ...] = variable\n",
    "\n",
    "    return out_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_sequence(sequences):\n",
    "\n",
    "    return torch.nn.utils.rnn.pack_padded_sequence(pad_sequence(sequences), [v.size(0) for v in sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convLayer(in_channels, out_channels, keep_prob=0.0):\n",
    "    \"\"\"3*3 convolution with padding,ever time call it the output size become half\"\"\"\n",
    "    cnn_seq = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "        nn.ReLU(True),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Dropout(keep_prob)\n",
    "    )\n",
    "    return cnn_seq\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, vector_dim, output_size, use_cuda, batch_size=1):\n",
    "        super(Classifier, self).__init__()\n",
    "        \"\"\"\n",
    "        Initial a muti-layer Bidirectional LSTM\n",
    "        :param layer_size: a list of each layer'size\n",
    "        :param batch_size: \n",
    "        :param vector_dim: \n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.vector_dim = vector_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.use_cuda = use_cuda\n",
    "        self.lstm = nn.LSTM(input_size=self.vector_dim, num_layers=self.num_layers, hidden_size=self.hidden_size, batch_first=False)\n",
    "        self.linear = nn.Linear(self.hidden_size, output_size)\n",
    "        self.hidden = self.init_hidden(self.use_cuda)\n",
    "\n",
    "    def init_hidden(self,use_cuda):\n",
    "        if use_cuda:\n",
    "            return (Variable(torch.zeros(self.lstm.num_layers, self.batch_size, self.lstm.hidden_size)).cuda(),\n",
    "                    Variable(torch.zeros(self.lstm.num_layers, self.batch_size, self.lstm.hidden_size)).cuda())\n",
    "        else:\n",
    "            return (Variable(torch.zeros(self.lstm.num_layers, self.batch_size, self.lstm.hidden_size)),\n",
    "                    Variable(torch.zeros(self.lstm.num_layers, self.batch_size, self.lstm.hidden_size)))\n",
    "\n",
    "    def repackage_hidden(self,h):\n",
    "        \"\"\"Wraps hidden states in new Variables, to detach them from their history.\"\"\"\n",
    "        if type(h) == Variable:\n",
    "            return Variable(h.data)\n",
    "        else:\n",
    "            return tuple(self.repackage_hidden(v) for v in h)\n",
    "    \n",
    "    def get_last_hidden(self, packed_seq):\n",
    "        #get last hidden state from packed sequence outputted from LSTM\n",
    "        seq = torch.nn.utils.rnn.pad_packed_sequence(packed_seq)\n",
    "        seq_data = seq[0]\n",
    "        seq_indices = seq[1]\n",
    "        seq_last_indices = [s-1 for s in seq_indices]\n",
    "        return seq_data[seq_last_indices, range(len(seq_indices)), :]\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        self.hidden = self.init_hidden(self.use_cuda)\n",
    "        output, self.hidden = self.lstm(inputs, self.hidden)\n",
    "        last_hidden = self.get_last_hidden(output)\n",
    "        return self.linear(last_hidden)\n",
    "\n",
    "class AttentionalClassify(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AttentionalClassify, self).__init__()\n",
    "\n",
    "    def forward(self, similarities, support_set_y):\n",
    "        \"\"\"\n",
    "        Products pdfs over the support set classes for the target set image.\n",
    "        :param similarities: A tensor with cosine similarites of size[batch_size,sequence_length]\n",
    "        :param support_set_y:[batch_size,sequence_length,classes_num]\n",
    "        :return: Softmax pdf shape[batch_size,classes_num]\n",
    "        \"\"\"\n",
    "        softmax = nn.Softmax()\n",
    "        softmax_similarities = softmax(similarities)\n",
    "        preds = softmax_similarities.unsqueeze(1).bmm(support_set_y).squeeze()\n",
    "        return preds\n",
    "\n",
    "class DistanceNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    This model calculates the cosine distance between each of the support set embeddings and the target image embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DistanceNetwork, self).__init__()\n",
    "\n",
    "    def forward(self, support_set, input_image):\n",
    "        \"\"\"\n",
    "        forward implement\n",
    "        :param support_set:the embeddings of the support set images.shape[sequence_length,batch_size,64]\n",
    "        :param input_image: the embedding of the target image,shape[batch_size,64]\n",
    "        :return:shape[batch_size,sequence_length]\n",
    "        \"\"\"\n",
    "        eps = 1e-10\n",
    "        similarities = []\n",
    "        for support_image in support_set:\n",
    "            sum_support = torch.sum(torch.pow(support_image, 2), 1)\n",
    "            support_manitude = sum_support.clamp(eps, float(\"inf\")).rsqrt()\n",
    "            dot_product = input_image.unsqueeze(1).bmm(support_image.unsqueeze(2)).squeeze()\n",
    "            cosine_similarity = dot_product * support_manitude\n",
    "            similarities.append(cosine_similarity)\n",
    "        similarities = torch.stack(similarities)\n",
    "        return similarities.t()\n",
    "\n",
    "class MatchingNetwork(nn.Module):\n",
    "    def __init__(self, vocab_size, batch_size=32, num_lstm_hidden=100, sequence_embedding_size=100, learning_rate=1e-3, num_classes_per_set=5, \\\n",
    "                 num_samples_per_class=1, input_embedding_dim=300, use_cuda=True):\n",
    "        \"\"\"\n",
    "        This is our main network\n",
    "        :param batch_size:\n",
    "        :param num_channels:\n",
    "        :param learning_rate:\n",
    "        :param fce: Flag indicating whether to use full context embeddings(i.e. apply an LSTM on the CNN embeddings)\n",
    "        :param num_classes_per_set:\n",
    "        :param num_samples_per_class:\n",
    "        :param image_size:\n",
    "        \"\"\"\n",
    "        super(MatchingNetwork, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_classes_per_set = num_classes_per_set\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.use_cuda = use_cuda\n",
    "        #todo: customize number of layers\n",
    "        self.g = Classifier(hidden_size=num_lstm_hidden, batch_size=self.batch_size, \n",
    "                         num_layers=1, vector_dim=input_embedding_dim, output_size=sequence_embedding_size, use_cuda=use_cuda)\n",
    "        self.dn = DistanceNetwork()\n",
    "        self.classify = AttentionalClassify()\n",
    "        self.embed = nn.Embedding(vocab_size, input_embedding_dim)\n",
    "\n",
    "    def pack_numpy_sequence(self, sequences):\n",
    "        #pack input sequence into pytorch's PackedSequence object\n",
    "        seq_temp = []\n",
    "        for seq in sequences:\n",
    "            unpadded_seq = seq[seq.nonzero()]\n",
    "            var = Variable(torch.from_numpy(unpadded_seq)).long()\n",
    "            var = var.cuda() if self.use_cuda else var\n",
    "            embedded_seq = self.embed(var)\n",
    "            seq_temp.append(embedded_seq)\n",
    "        #add index, need to sort back later\n",
    "        indices = range(len(seq_temp))\n",
    "        #sort by size\n",
    "        seq_temp = sorted(list(zip(seq_temp,indices)), key=lambda s:len(s[0]), reverse=True)\n",
    "        seq_sorted = list(zip(*seq_temp))\n",
    "        return pack_sequence(seq_sorted[0]), seq_sorted[1]\n",
    "    \n",
    "    def forward(self, support_set_images, support_set_y_one_hot, target_image, target_y):\n",
    "        \"\"\"\n",
    "        Main process of the network\n",
    "        :param support_set_images: shape[batch_size,sequence_length,num_channels,image_size,image_size]\n",
    "        :param support_set_y_one_hot: shape[batch_size,sequence_length,num_classes_per_set]\n",
    "        :param target_image: shape[batch_size,num_channels,image_size,image_size]\n",
    "        :param target_y:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # produce embeddings for support set images\n",
    "        encoded_images = []\n",
    "        for i in np.arange(support_set_images.shape[1]):\n",
    "            sequences = support_set_images[:, i, :]\n",
    "            packed_seq, indices = self.pack_numpy_sequence(sequences)\n",
    "            gen_encode = self.g(packed_seq)\n",
    "            #sort the sequences back\n",
    "            reordered = gen_encode[indices,:]\n",
    "            encoded_images.append(reordered)\n",
    "\n",
    "        # produce embeddings for target images\n",
    "        packed_seq, indices = self.pack_numpy_sequence(target_image)\n",
    "        gen_encode = self.g(packed_seq)\n",
    "        reordered = gen_encode[indices,:]\n",
    "        #sort the sequences back\n",
    "        encoded_images.append(reordered)\n",
    "        output = torch.stack(encoded_images)\n",
    "\n",
    "        # get similarities between support set embeddings and target\n",
    "        similarities = self.dn(support_set=output[:-1], input_image=output[-1])\n",
    "\n",
    "#         print(similarities)\n",
    "\n",
    "        # produce predictions for target probabilities\n",
    "        preds = self.classify(similarities, support_set_y=support_set_y_one_hot)\n",
    "\n",
    "        # calculate the accuracy\n",
    "        values, indices = preds.max(1)\n",
    "        accuracy = torch.mean((indices.squeeze() == target_y).float())\n",
    "        crossentropy_loss = F.cross_entropy(preds, target_y.long())\n",
    "\n",
    "        return accuracy, crossentropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y, classes):\n",
    "    b = np.zeros([*y.shape,classes])\n",
    "    for i in range(len(b)):\n",
    "        b[i, np.arange(y[i].shape[0]), y[i]] = 1\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeBankBuilder:\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Initializes the experiment\n",
    "        :param data:\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "\n",
    "    def build_experiment(self, batch_size, num_lstm_hidden, sequence_embedding_size, input_embedding_dim, lr, \n",
    "                         classes_per_set, samples_per_class, keep_prob,\n",
    "                        optim, weight_decay, use_cuda):\n",
    "        \"\"\"\n",
    "\n",
    "        :param batch_size:\n",
    "        :param num_channels:\n",
    "        :param lr:\n",
    "        :param image_size:\n",
    "        :param classes_per_set:\n",
    "        :param samples_per_class:\n",
    "        :param keep_prob:\n",
    "        :param fce:\n",
    "        :param optim:\n",
    "        :param weight_decay:\n",
    "        :param use_cuda:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.classes_per_set = classes_per_set\n",
    "        self.sample_per_class = samples_per_class\n",
    "        self.keep_prob = keep_prob\n",
    "        self.batch_size = batch_size\n",
    "        self.num_lstm_hidden = num_lstm_hidden\n",
    "        self.sequence_embedding_size = sequence_embedding_size\n",
    "        self.input_embedding_dim = input_embedding_dim\n",
    "        self.lr = lr\n",
    "        self.optim = optim\n",
    "        self.wd = weight_decay\n",
    "        self.isCuadAvailable = torch.cuda.is_available()\n",
    "        self.use_cuda = use_cuda\n",
    "        self.matchNet = MatchingNetwork(len(self.data.word_to_idx), \n",
    "                                        batch_size=batch_size, \n",
    "                                        num_lstm_hidden=num_lstm_hidden, \n",
    "                                        learning_rate=self.lr,\n",
    "                                        sequence_embedding_size=sequence_embedding_size, \n",
    "                                        input_embedding_dim=input_embedding_dim,\n",
    "                                        num_classes_per_set = classes_per_set,\n",
    "                                        num_samples_per_class= samples_per_class,\n",
    "                                        use_cuda = self.isCuadAvailable & self.use_cuda)\n",
    "        self.total_iter = 0\n",
    "        if self.isCuadAvailable & self.use_cuda:\n",
    "            cudnn.benchmark = True  # set True to speedup\n",
    "            torch.cuda.manual_seed_all(2017)\n",
    "            self.matchNet.cuda()\n",
    "        self.total_train_iter = 0\n",
    "        self.optimizer = self._create_optimizer(self.matchNet, self.lr)\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer, 'min',verbose=True)\n",
    "\n",
    "    def run_training_epoch(self, total_train_batches):\n",
    "        \"\"\"\n",
    "        Run the training epoch\n",
    "        :param total_train_batches: Number of batches to train on\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        total_c_loss = 0.0\n",
    "        total_accuracy = 0.0\n",
    "        # optimizer = self._create_optimizer(self.matchNet, self.lr)\n",
    "\n",
    "        with tqdm.tqdm(total=total_train_batches) as pbar:\n",
    "            for i in range(total_train_batches):\n",
    "                x_support, y_support, x_target, y_target = self.data.get_train_batch()\n",
    "\n",
    "                y_target = Variable(torch.from_numpy(y_target), requires_grad=False).squeeze().long()\n",
    "                y_support = Variable(torch.from_numpy(one_hot(y_support, classes_per_set)).float(), requires_grad=False)\n",
    "                if self.isCuadAvailable & self.use_cuda:\n",
    "                    acc, c_loss = self.matchNet(x_support, y_support.cuda(), x_target,\n",
    "                                                y_target.cuda())\n",
    "                else:\n",
    "                    acc, c_loss = self.matchNet(x_support, y_support, x_target, y_target)\n",
    "\n",
    "                # optimize process\n",
    "                self.optimizer.zero_grad()\n",
    "                c_loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # TODO: update learning rate?\n",
    "\n",
    "                iter_out = \"tr_loss: {}, tr_accuracy: {}\".format(c_loss.data[0], acc.data[0])\n",
    "                pbar.set_description(iter_out)\n",
    "                pbar.update(1)\n",
    "                total_c_loss += c_loss.data[0]\n",
    "                total_accuracy += acc.data[0]\n",
    "                # self.total_train_iter+=1\n",
    "\n",
    "            total_c_loss = total_c_loss / total_train_batches\n",
    "            total_accuracy = total_accuracy / total_train_batches\n",
    "            return total_c_loss, total_accuracy\n",
    "\n",
    "    def _create_optimizer(self, model, lr):\n",
    "        # setup optimizer\n",
    "        if self.optim == \"adam\":\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=self.wd)\n",
    "        elif self.optim == \"sgd\":\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, dampening=0.9, weight_decay=self.wd)\n",
    "        else:\n",
    "            raise Exception(\"Not a valid optimizer offered: {0}\".format(self.optim))\n",
    "        return optimizer\n",
    "\n",
    "    def _adjust_learning_rate(self, optimizer):\n",
    "        \"\"\"\n",
    "        Update the learning rate after some epochs\n",
    "        :param optimizer:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "    def run_val_epoch(self, total_val_batches):\n",
    "        \"\"\"\n",
    "        Run the training epoch\n",
    "        :param total_train_batches: Number of batches to train on\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        total_c_loss = 0.0\n",
    "        total_accuracy = 0.0\n",
    "\n",
    "        with tqdm.tqdm(total=total_val_batches) as pbar:\n",
    "            for i in range(total_val_batches):\n",
    "                x_support, y_support, x_target, y_target = self.data.get_val_batch()\n",
    "\n",
    "                y_target = Variable(torch.from_numpy(y_target), requires_grad=False).squeeze().long()\n",
    "                y_support = Variable(torch.from_numpy(one_hot(y_support, classes_per_set)).float(), requires_grad=False)\n",
    "                if self.isCuadAvailable & self.use_cuda:\n",
    "                    acc, c_loss = self.matchNet(x_support, y_support.cuda(), x_target,\n",
    "                                                y_target.cuda())\n",
    "                else:\n",
    "                    acc, c_loss = self.matchNet(x_support, y_support, x_target, y_target)\n",
    "\n",
    "                iter_out = \"val_loss: {}, val_accuracy: {}\".format(c_loss.data[0], acc.data[0])\n",
    "                pbar.set_description(iter_out)\n",
    "                pbar.update(1)\n",
    "                total_c_loss += c_loss.data[0]\n",
    "                total_accuracy += acc.data[0]\n",
    "\n",
    "            total_c_loss = total_c_loss / total_val_batches\n",
    "            total_accuracy = total_accuracy / total_val_batches\n",
    "            self.scheduler.step(total_c_loss)\n",
    "            return total_c_loss, total_accuracy\n",
    "\n",
    "    def run_test_epoch(self, total_test_batches):\n",
    "        \"\"\"\n",
    "        Run the training epoch\n",
    "        :param total_train_batches: Number of batches to train on\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        total_c_loss = 0.0\n",
    "        total_accuracy = 0.0\n",
    "\n",
    "        with tqdm.tqdm(total=total_test_batches) as pbar:\n",
    "            for i in range(total_test_batches):\n",
    "                x_support, y_support, x_target, y_target = self.data.get_test_batch()\n",
    "\n",
    "                y_target = Variable(torch.from_numpy(y_target), requires_grad=False).squeeze().long()\n",
    "                y_support = Variable(torch.from_numpy(one_hot(y_support, classes_per_set)).float(), requires_grad=False)\n",
    "                if self.isCuadAvailable & self.use_cuda:\n",
    "                    acc, c_loss = self.matchNet(x_support, y_support.cuda(), x_target,\n",
    "                                                y_target.cuda())\n",
    "                else:\n",
    "                    acc, c_loss = self.matchNet(x_support, y_support, x_target, y_target)\n",
    "\n",
    "                # TODO: update learning rate?\n",
    "\n",
    "                iter_out = \"val_loss: {}, val_accuracy: {}\".format(c_loss.data[0], acc.data[0])\n",
    "                pbar.set_description(iter_out)\n",
    "                pbar.update(1)\n",
    "                total_c_loss += c_loss.data[0]\n",
    "                total_accuracy += acc.data[0]\n",
    "                # self.total_train_iter+=1\n",
    "\n",
    "            total_c_loss = total_c_loss / total_test_batches\n",
    "            total_accuracy = total_accuracy / total_test_batches\n",
    "            return total_c_loss, total_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment setup\n",
    "batch_size = 8\n",
    "# fce = True\n",
    "classes_per_set = 5\n",
    "samples_per_class = 1\n",
    "channels = 1\n",
    "# Training setup\n",
    "total_epochs = 100\n",
    "total_train_batches = 1000\n",
    "total_val_batches = 250\n",
    "total_test_batches = 500\n",
    "best_val_acc = 0.0\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Vocabs\n",
      "Vocab processed, 9339 words in total\n",
      "max sequence length = 122\n"
     ]
    }
   ],
   "source": [
    "data = TreeBankDataset(batch_size=batch_size, classes_per_set=classes_per_set,\n",
    "                            samples_per_class=samples_per_class, seed=2017, shuffle=True, use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_oneShotBuilder = TreeBankBuilder(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_oneShotBuilder.build_experiment(batch_size=batch_size, num_lstm_hidden=100, sequence_embedding_size=100, input_embedding_dim=300, \n",
    "                                    lr=1e-3,  classes_per_set=classes_per_set,\n",
    "                                    samples_per_class=samples_per_class, keep_prob=1, optim=\"adam\", weight_decay=0,\n",
    "                                    use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tr_loss: 1.625262975692749, tr_accuracy: 0.125: 100%|██████████| 1000/1000 [02:32<00:00,  6.45it/s]\n",
      "tr_loss: 1.578507661819458, tr_accuracy: 0.375:   0%|          | 1/1000 [00:00<02:27,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6146310504674912 0.196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tr_loss: 1.5939922332763672, tr_accuracy: 0.125: 100%|██████████| 1000/1000 [02:25<00:00,  7.52it/s]\n",
      "tr_loss: 1.6421555280685425, tr_accuracy: 0.0:   0%|          | 1/1000 [00:00<02:18,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6130730344057083 0.196875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tr_loss: 1.6031792163848877, tr_accuracy: 0.25:  80%|████████  | 802/1000 [02:02<00:30,  6.40it/s] "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    total_c_loss, total_accuracy = obj_oneShotBuilder.run_training_epoch(1000)\n",
    "    print(total_c_loss, total_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = MatchingNetwork(vocab_size = len(data.word_to_idx), batch_size=batch_size, use_cuda=use_cuda, input_embedding_dim=300)\n",
    "\n",
    "# support_x, support_y, target_x, target_y =  data.get_train_batch()\n",
    "\n",
    "# target_y = Variable(torch.from_numpy(target_y), requires_grad=False).squeeze().long()\n",
    "# support_y = Variable(torch.from_numpy(one_hot(support_y, classes_per_set)).float(), requires_grad=False)\n",
    "\n",
    "# if use_cuda:\n",
    "#     net.cuda()\n",
    "#     target_y = target_y.cuda()\n",
    "#     support_y = support_y.cuda()\n",
    "\n",
    "# net(support_x, support_y, target_x, target_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
