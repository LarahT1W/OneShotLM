
C:\Users\Alfred\Jupyter\matchingnet - Copy\New folder (4)>python mymainfornlp.py
[nltk_data] Downloading package treebank to
[nltk_data]     C:\Users\Alfred\AppData\Roaming\nltk_data...
[nltk_data]   Package treebank is already up-to-date!
[nltk_data] Downloading package stopwords to
[nltk_data]     C:\Users\Alfred\AppData\Roaming\nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
3914
11969
1044
Last month , Judge Curry set the interest rate on the refund at 9 % .
The Austin , Texas-based company , which specializes in the direct sale of <blank_token> computers and accessories , said 0 its price cuts include a $ 100 reduction on its System 210 computer with 512 kilobytes of memory , a 40-megabyte hard disk and a color monitor . personal
Taking a cue from California , more politicians will launch their campaigns by backing initiatives , says 0 <blank_token> Magleby of Brigham Young University . David
In the year-ago quarter , the company <blank_token> net income of $ 1.9 million , or 29 cents a share . reported
The firm and Mr. Whelen allegedly sold securities to the public at <blank_token> prices , among other alleged violations . unfair
The move boosts Intelogic Chairman Asher Edelman 's stake to 20 % from 16.2 % and may help <blank_token> Martin Ackerman from making a run at the computer-services concern . prevent
At one point , Hammersmith is <blank_token> to have accounted for as much as 10 % of the sterling market in interest-rate swap dealings . reported
Batch  0 : loss= 10.00797176361084
Batch  1 : loss= 9.6901216506958
Batch  2 : loss= 9.330536842346191
Batch  3 : loss= 8.936923027038574
Batch  4 : loss= 8.494110107421875
Batch  5 : loss= 8.142143249511719
Batch  6 : loss= 7.744637966156006
Batch  7 : loss= 7.360684871673584
Batch  8 : loss= 7.230204105377197
Batch  9 : loss= 6.818558216094971
Batch  10 : loss= 6.760748386383057
Batch  11 : loss= 6.4253106117248535
Batch  12 : loss= 6.302291393280029
Batch  13 : loss= 6.0397257804870605
Batch  14 : loss= 5.994900226593018
Batch  15 : loss= 5.89233922958374
Batch  16 : loss= 5.206881523132324
Batch  17 : loss= 5.003508567810059
Batch  18 : loss= 4.793251991271973
Train: Epoch  0 : loss= 7.16709734264173
Batch  0 : loss= 1.5445233583450317  acc= 0.4000000059604645
Batch  1 : loss= 1.5545583963394165  acc= 0.2800000011920929
Batch  2 : loss= 1.6070818901062012  acc= 0.18000000715255737
Batch  3 : loss= 1.5198231935501099  acc= 0.3400000035762787
Train: Epoch  0 : loss= 1.5564967095851898  acc= 0.30000000447034836
Batch  0 : loss= 1.585991382598877  acc= 0.30000001192092896
Batch  1 : loss= 1.5764236450195312  acc= 0.2800000011920929
Batch  2 : loss= 1.5776771306991577  acc= 0.36000001430511475
Batch  3 : loss= 1.5729691982269287  acc= 0.2800000011920929
Batch  4 : loss= 1.551742672920227  acc= 0.3799999952316284
Batch  5 : loss= 1.5389291048049927  acc= 0.3799999952316284
Batch  6 : loss= 1.5404318571090698  acc= 0.41999998688697815
Batch  7 : loss= 1.5314202308654785  acc= 0.3799999952316284
Test: Epoch  0 : loss= 1.5594481527805328  acc= 0.3475000001490116
Batch  0 : loss= 4.844322204589844
Batch  1 : loss= 4.840137004852295
Batch  2 : loss= 4.724723815917969
Batch  3 : loss= 4.575462818145752
Batch  4 : loss= 4.532820224761963
Batch  5 : loss= 4.512051582336426
Batch  6 : loss= 4.296318054199219
Batch  7 : loss= 4.475581169128418
Batch  8 : loss= 4.344564437866211
Batch  9 : loss= 4.2080583572387695
Batch  10 : loss= 4.582901477813721
Batch  11 : loss= 4.322665691375732
Batch  12 : loss= 4.247835159301758
Batch  13 : loss= 4.08591365814209
Batch  14 : loss= 4.08782958984375
Batch  15 : loss= 3.8575143814086914
Batch  16 : loss= 3.852200508117676
Batch  17 : loss= 3.704789400100708
Train: Epoch  1 : loss= 4.338649418618944
Batch  0 : loss= 1.5526701211929321  acc= 0.3799999952316284
Batch  1 : loss= 1.5385056734085083  acc= 0.3799999952316284
Batch  2 : loss= 1.590397596359253  acc= 0.30000001192092896
Batch  3 : loss= 1.5632580518722534  acc= 0.3199999928474426
Train: Epoch  1 : loss= 1.5612078607082367  acc= 0.3449999988079071
Batch  0 : loss= 1.5450705289840698  acc= 0.36000001430511475
Batch  1 : loss= 1.5518215894699097  acc= 0.4000000059604645
Batch  2 : loss= 1.5824589729309082  acc= 0.3400000035762787
Batch  3 : loss= 1.5285547971725464  acc= 0.46000000834465027
Batch  4 : loss= 1.5894081592559814  acc= 0.23999999463558197
Batch  5 : loss= 1.5605932474136353  acc= 0.25999999046325684
Batch  6 : loss= 1.5633326768875122  acc= 0.3799999952316284
Batch  7 : loss= 1.602379322052002  acc= 0.20000000298023224
Test: Epoch  1 : loss= 1.5654524117708206  acc= 0.33000000193715096
Batch  0 : loss= 3.937082529067993
Batch  1 : loss= 4.159244060516357
Batch  2 : loss= 3.857813596725464
Batch  3 : loss= 4.0076422691345215
Batch  4 : loss= 3.8386483192443848
Batch  5 : loss= 3.926372528076172
Batch  6 : loss= 3.6372625827789307
Batch  7 : loss= 3.904582977294922
Batch  8 : loss= 3.593768358230591
Batch  9 : loss= 3.6434428691864014
Batch  10 : loss= 3.5747406482696533
Batch  11 : loss= 3.4019110202789307
Batch  12 : loss= 3.4475042819976807
Batch  13 : loss= 3.352220296859741
Batch  14 : loss= 3.331477642059326
Batch  15 : loss= 3.5631723403930664
Batch  16 : loss= 3.4502029418945312
Train: Epoch  2 : loss= 3.6839464271769806
Batch  0 : loss= 1.5500973463058472  acc= 0.4399999976158142
Batch  1 : loss= 1.4986584186553955  acc= 0.5400000214576721
Batch  2 : loss= 1.5311007499694824  acc= 0.47999998927116394
Batch  3 : loss= 1.5175033807754517  acc= 0.4000000059604645
Train: Epoch  2 : loss= 1.5243399739265442  acc= 0.4650000035762787
Batch  0 : loss= 1.6028683185577393  acc= 0.2199999988079071
Batch  1 : loss= 1.5469512939453125  acc= 0.36000001430511475
Batch  2 : loss= 1.5376625061035156  acc= 0.30000001192092896
Batch  3 : loss= 1.569445013999939  acc= 0.23999999463558197
Batch  4 : loss= 1.5646826028823853  acc= 0.3799999952316284
Batch  5 : loss= 1.6114085912704468  acc= 0.23999999463558197
Batch  6 : loss= 1.5583763122558594  acc= 0.30000001192092896
Batch  7 : loss= 1.5193612575531006  acc= 0.36000001430511475
Test: Epoch  2 : loss= 1.5638444870710373  acc= 0.30000000447034836
Batch  0 : loss= 3.2648727893829346
Batch  1 : loss= 3.5160646438598633
Batch  2 : loss= 3.4697115421295166
Batch  3 : loss= 3.387160062789917
Batch  4 : loss= 3.4074296951293945
Batch  5 : loss= 3.3646087646484375
Batch  6 : loss= 3.243495225906372
Batch  7 : loss= 3.2554211616516113
Batch  8 : loss= 3.2033116817474365
Batch  9 : loss= 3.008312463760376
Batch  10 : loss= 3.1361465454101562
Batch  11 : loss= 3.021003484725952
Batch  12 : loss= 2.9889774322509766
Batch  13 : loss= 3.1304030418395996
Batch  14 : loss= 3.0698695182800293
Batch  15 : loss= 3.018588066101074
Train: Epoch  3 : loss= 3.217836007475853
Batch  0 : loss= 1.4861172437667847  acc= 0.5400000214576721
Batch  1 : loss= 1.5388163328170776  acc= 0.4000000059604645
Batch  2 : loss= 1.5554050207138062  acc= 0.4000000059604645
Batch  3 : loss= 1.5610820055007935  acc= 0.3400000035762787
Train: Epoch  3 : loss= 1.5353551506996155  acc= 0.42000000923871994
Batch  0 : loss= 1.519392967224121  acc= 0.41999998688697815
Batch  1 : loss= 1.555139183998108  acc= 0.2800000011920929
Batch  2 : loss= 1.551783561706543  acc= 0.41999998688697815
Batch  3 : loss= 1.5863667726516724  acc= 0.20000000298023224
Batch  4 : loss= 1.5881659984588623  acc= 0.25999999046325684
Batch  5 : loss= 1.550841212272644  acc= 0.3400000035762787
Batch  6 : loss= 1.5857794284820557  acc= 0.30000001192092896
Batch  7 : loss= 1.5451240539550781  acc= 0.3199999928474426
Test: Epoch  3 : loss= 1.5603241473436356  acc= 0.31749999709427357
Batch  0 : loss= 3.21026349067688
Batch  1 : loss= 3.2909915447235107
Batch  2 : loss= 2.9721200466156006
Batch  3 : loss= 3.2171504497528076
Batch  4 : loss= 2.9837534427642822
Batch  5 : loss= 3.085381269454956
Batch  6 : loss= 2.8762717247009277
Batch  7 : loss= 2.8893983364105225
Batch  8 : loss= 2.8823392391204834
Batch  9 : loss= 2.739647626876831
Batch  10 : loss= 2.7883803844451904
Batch  11 : loss= 2.7971231937408447
Batch  12 : loss= 2.8995585441589355
Batch  13 : loss= 2.657789468765259
Batch  14 : loss= 2.8609657287597656
Train: Epoch  4 : loss= 2.943408966064453
Batch  0 : loss= 1.531803846359253  acc= 0.5199999809265137
Batch  1 : loss= 1.5338797569274902  acc= 0.3400000035762787
Batch  2 : loss= 1.5518684387207031  acc= 0.3799999952316284
Batch  3 : loss= 1.557655692100525  acc= 0.3400000035762787
Batch  4 : loss= 1.5368915796279907  acc= 0.3400000035762787
Train: Epoch  4 : loss= 1.5424198627471923  acc= 0.38399999737739565
Batch  0 : loss= 1.5683099031448364  acc= 0.30000001192092896
Batch  1 : loss= 1.5831376314163208  acc= 0.20000000298023224
Batch  2 : loss= 1.581322193145752  acc= 0.25999999046325684
Batch  3 : loss= 1.5953630208969116  acc= 0.25999999046325684
Batch  4 : loss= 1.5764775276184082  acc= 0.25999999046325684
Batch  5 : loss= 1.578800916671753  acc= 0.3199999928474426
Batch  6 : loss= 1.5300581455230713  acc= 0.46000000834465027
Batch  7 : loss= 1.5792843103408813  acc= 0.25999999046325684
Test: Epoch  4 : loss= 1.5740942060947418  acc= 0.2899999972432852
Batch  0 : loss= 3.161432981491089
Batch  1 : loss= 3.000706672668457
Batch  2 : loss= 2.923996686935425
Batch  3 : loss= 2.9739701747894287
Batch  4 : loss= 2.785963773727417
Batch  5 : loss= 2.8648524284362793
Batch  6 : loss= 2.7576558589935303
Batch  7 : loss= 2.6387901306152344
Batch  8 : loss= 2.696166753768921
Batch  9 : loss= 2.611297369003296
Batch  10 : loss= 2.613372564315796
Batch  11 : loss= 2.6444168090820312
Batch  12 : loss= 2.616035223007202
Batch  13 : loss= 2.552058458328247
Train: Epoch  5 : loss= 2.7743368489401683
Batch  0 : loss= 1.4981776475906372  acc= 0.5
Batch  1 : loss= 1.5424413681030273  acc= 0.36000001430511475
Batch  2 : loss= 1.5164310932159424  acc= 0.5
Batch  3 : loss= 1.5096622705459595  acc= 0.4399999976158142
Batch  4 : loss= 1.5201259851455688  acc= 0.3799999952316284
Train: Epoch  5 : loss= 1.517367672920227  acc= 0.4360000014305115
Batch  0 : loss= 1.5618435144424438  acc= 0.3199999928474426
Batch  1 : loss= 1.5645793676376343  acc= 0.2800000011920929
Batch  2 : loss= 1.5120996236801147  acc= 0.4399999976158142
Batch  3 : loss= 1.57097589969635  acc= 0.4000000059604645
Batch  4 : loss= 1.5673328638076782  acc= 0.23999999463558197
Batch  5 : loss= 1.5701088905334473  acc= 0.30000001192092896
Batch  6 : loss= 1.5784199237823486  acc= 0.23999999463558197
Batch  7 : loss= 1.5434699058532715  acc= 0.36000001430511475
Test: Epoch  5 : loss= 1.558603748679161  acc= 0.32250000163912773
Batch  0 : loss= 2.9369616508483887
Batch  1 : loss= 3.004434108734131
Batch  2 : loss= 2.7847719192504883
Batch  3 : loss= 2.8896102905273438
Batch  4 : loss= 2.6963980197906494
Batch  5 : loss= 2.7234292030334473
Batch  6 : loss= 2.597196340560913
Batch  7 : loss= 2.599611282348633
Batch  8 : loss= 2.4709677696228027
Batch  9 : loss= 2.5333220958709717
Batch  10 : loss= 2.501979351043701
Batch  11 : loss= 2.4499149322509766
Batch  12 : loss= 2.567812919616699
Train: Epoch  6 : loss= 2.673569991038396
Batch  0 : loss= 1.530426025390625  acc= 0.46000000834465027
Batch  1 : loss= 1.5171433687210083  acc= 0.4000000059604645
Batch  2 : loss= 1.5334649085998535  acc= 0.3199999928474426
Batch  3 : loss= 1.4962859153747559  acc= 0.5
Batch  4 : loss= 1.5164551734924316  acc= 0.41999998688697815
Train: Epoch  6 : loss= 1.5187550783157349  acc= 0.4199999988079071
Batch  0 : loss= 1.5923831462860107  acc= 0.23999999463558197
Batch  1 : loss= 1.5499516725540161  acc= 0.36000001430511475
Batch  2 : loss= 1.566085934638977  acc= 0.2800000011920929
Batch  3 : loss= 1.5837600231170654  acc= 0.25999999046325684
Batch  4 : loss= 1.5966923236846924  acc= 0.3400000035762787
Batch  5 : loss= 1.6165833473205566  acc= 0.18000000715255737
Batch  6 : loss= 1.574879765510559  acc= 0.23999999463558197
Batch  7 : loss= 1.5876623392105103  acc= 0.3199999928474426
Test: Epoch  6 : loss= 1.5834998190402985  acc= 0.2774999998509884
Batch  0 : loss= 2.639126777648926
Batch  1 : loss= 2.8291237354278564
Batch  2 : loss= 2.7919135093688965
Batch  3 : loss= 2.8179478645324707
Batch  4 : loss= 2.5829620361328125
Batch  5 : loss= 2.667869806289673
Batch  6 : loss= 2.4728994369506836
Batch  7 : loss= 2.5531420707702637
Batch  8 : loss= 2.4231081008911133
Batch  9 : loss= 2.3824594020843506
Batch  10 : loss= 2.389458179473877
Batch  11 : loss= 2.404622793197632
Train: Epoch  7 : loss= 2.5795528093973794
Batch  0 : loss= 1.5184614658355713  acc= 0.36000001430511475
Batch  1 : loss= 1.5723079442977905  acc= 0.3199999928474426
Batch  2 : loss= 1.5086784362792969  acc= 0.46000000834465027
Batch  3 : loss= 1.446831226348877  acc= 0.6200000047683716
Batch  4 : loss= 1.468982219696045  acc= 0.5400000214576721
Train: Epoch  7 : loss= 1.503052258491516  acc= 0.46000000834465027
Batch  0 : loss= 1.5460309982299805  acc= 0.36000001430511475
Batch  1 : loss= 1.6143020391464233  acc= 0.14000000059604645
Batch  2 : loss= 1.5556461811065674  acc= 0.3799999952316284
Batch  3 : loss= 1.547591209411621  acc= 0.3199999928474426
Batch  4 : loss= 1.5610530376434326  acc= 0.36000001430511475
Batch  5 : loss= 1.5485022068023682  acc= 0.25999999046325684
Batch  6 : loss= 1.5856982469558716  acc= 0.2800000011920929
Batch  7 : loss= 1.5522717237472534  acc= 0.30000001192092896
Test: Epoch  7 : loss= 1.5638869553804398  acc= 0.3000000026077032
Batch  0 : loss= 2.570068359375
Batch  1 : loss= 2.7194430828094482
Batch  2 : loss= 2.6730449199676514
Batch  3 : loss= 2.5432562828063965
Batch  4 : loss= 2.6511998176574707
Batch  5 : loss= 2.576352596282959
Batch  6 : loss= 2.4402029514312744
Batch  7 : loss= 2.41574764251709
Batch  8 : loss= 2.356358289718628
Batch  9 : loss= 2.297976016998291
Batch  10 : loss= 2.4117369651794434
Train: Epoch  8 : loss= 2.514126084067605
Batch  0 : loss= 1.565675973892212  acc= 0.3400000035762787
Batch  1 : loss= 1.4757713079452515  acc= 0.6600000262260437
Batch  2 : loss= 1.5005004405975342  acc= 0.5799999833106995
Batch  3 : loss= 1.5470099449157715  acc= 0.3400000035762787
Batch  4 : loss= 1.518834114074707  acc= 0.5
Train: Epoch  8 : loss= 1.5215583562850952  acc= 0.4840000033378601
Batch  0 : loss= 1.5786763429641724  acc= 0.25999999046325684
Batch  1 : loss= 1.5189502239227295  acc= 0.3799999952316284
Batch  2 : loss= 1.6005182266235352  acc= 0.18000000715255737
Batch  3 : loss= 1.553360104560852  acc= 0.3400000035762787
Batch  4 : loss= 1.5853022336959839  acc= 0.2800000011920929
Batch  5 : loss= 1.5402891635894775  acc= 0.36000001430511475
Batch  6 : loss= 1.5484598875045776  acc= 0.3199999928474426
Batch  7 : loss= 1.561331033706665  acc= 0.25999999046325684
Test: Epoch  8 : loss= 1.5608609020709991  acc= 0.29749999940395355
Batch  0 : loss= 2.576908826828003
Batch  1 : loss= 2.4613420963287354
Batch  2 : loss= 2.6171138286590576
Batch  3 : loss= 2.5366177558898926
Batch  4 : loss= 2.4285757541656494
Batch  5 : loss= 2.522251605987549
Batch  6 : loss= 2.4221179485321045
Batch  7 : loss= 2.3516933917999268
Batch  8 : loss= 2.3724429607391357
Batch  9 : loss= 2.426362991333008
Train: Epoch  9 : loss= 2.471542716026306
Batch  0 : loss= 1.4523370265960693  acc= 0.6200000047683716
Batch  1 : loss= 1.4741021394729614  acc= 0.5799999833106995
Batch  2 : loss= 1.4842267036437988  acc= 0.46000000834465027
Batch  3 : loss= 1.543061375617981  acc= 0.46000000834465027
Batch  4 : loss= 1.5141352415084839  acc= 0.5199999809265137
Batch  5 : loss= 1.539198637008667  acc= 0.41999998688697815
Train: Epoch  9 : loss= 1.5011768539746602  acc= 0.5099999954303106
Batch  0 : loss= 1.549454689025879  acc= 0.3400000035762787
Batch  1 : loss= 1.556799054145813  acc= 0.36000001430511475
Batch  2 : loss= 1.6000971794128418  acc= 0.23999999463558197
Batch  3 : loss= 1.5191844701766968  acc= 0.3400000035762787
Batch  4 : loss= 1.5592913627624512  acc= 0.3400000035762787
Batch  5 : loss= 1.5618493556976318  acc= 0.3199999928474426
Batch  6 : loss= 1.592524766921997  acc= 0.25999999046325684
Batch  7 : loss= 1.5185952186584473  acc= 0.41999998688697815
Test: Epoch  9 : loss= 1.5572245121002197  acc= 0.3274999987334013
Batch  0 : loss= 2.447120428085327
Batch  1 : loss= 2.65006160736084
Batch  2 : loss= 2.4933090209960938
Batch  3 : loss= 2.616865396499634
Batch  4 : loss= 2.4949207305908203
Batch  5 : loss= 2.4989728927612305
Batch  6 : loss= 2.476231575012207
Batch  7 : loss= 2.334690809249878
Batch  8 : loss= 2.3238954544067383
Train: Epoch  10 : loss= 2.4817853238847523
Batch  0 : loss= 1.4462089538574219  acc= 0.6800000071525574
Batch  1 : loss= 1.5211127996444702  acc= 0.4000000059604645
Batch  2 : loss= 1.4795989990234375  acc= 0.5400000214576721
Batch  3 : loss= 1.481598973274231  acc= 0.4399999976158142
Batch  4 : loss= 1.4787042140960693  acc= 0.47999998927116394
Batch  5 : loss= 1.4629712104797363  acc= 0.5799999833106995
Train: Epoch  10 : loss= 1.4783658583958943  acc= 0.5200000007947286
Batch  0 : loss= 1.552772045135498  acc= 0.36000001430511475
Batch  1 : loss= 1.571234107017517  acc= 0.3199999928474426
Batch  2 : loss= 1.5783989429473877  acc= 0.30000001192092896
Batch  3 : loss= 1.5569233894348145  acc= 0.2800000011920929
Batch  4 : loss= 1.613890528678894  acc= 0.20000000298023224
Batch  5 : loss= 1.5808442831039429  acc= 0.3199999928474426
Batch  6 : loss= 1.5380092859268188  acc= 0.25999999046325684
Batch  7 : loss= 1.592753291130066  acc= 0.30000001192092896
Test: Epoch  10 : loss= 1.5731032341718674  acc= 0.29250000230968
Batch  0 : loss= 2.5757246017456055
Batch  1 : loss= 2.6910927295684814
Batch  2 : loss= 2.394519329071045
Batch  3 : loss= 2.546924352645874
Batch  4 : loss= 2.5242185592651367
Batch  5 : loss= 2.484187364578247
Batch  6 : loss= 2.395470380783081
Batch  7 : loss= 2.4209723472595215
Train: Epoch  11 : loss= 2.504138708114624
Batch  0 : loss= 1.5125854015350342  acc= 0.5
Batch  1 : loss= 1.4880272150039673  acc= 0.5600000023841858
Batch  2 : loss= 1.5073144435882568  acc= 0.5199999809265137
Batch  3 : loss= 1.4610130786895752  acc= 0.6000000238418579
Batch  4 : loss= 1.4743298292160034  acc= 0.47999998927116394
Batch  5 : loss= 1.4628987312316895  acc= 0.5600000023841858
Train: Epoch  11 : loss= 1.4843614498774211  acc= 0.5366666664679846
Batch  0 : loss= 1.5567574501037598  acc= 0.25999999046325684
Batch  1 : loss= 1.5378923416137695  acc= 0.36000001430511475
Batch  2 : loss= 1.5068391561508179  acc= 0.3799999952316284
Batch  3 : loss= 1.5583480596542358  acc= 0.3199999928474426
Batch  4 : loss= 1.5474101305007935  acc= 0.3400000035762787
Batch  5 : loss= 1.5270951986312866  acc= 0.3199999928474426
Batch  6 : loss= 1.5347613096237183  acc= 0.3799999952316284
Batch  7 : loss= 1.5633883476257324  acc= 0.30000001192092896
Test: Epoch  11 : loss= 1.5415614992380142  acc= 0.33249999955296516
Batch  0 : loss= 2.488823413848877
Batch  1 : loss= 2.525590419769287
Batch  2 : loss= 2.5148401260375977
Batch  3 : loss= 2.352383613586426
Batch  4 : loss= 2.4502577781677246
Batch  5 : loss= 2.387286901473999
Batch  6 : loss= 2.396138906478882
Train: Epoch  12 : loss= 2.4450458799089705
Batch  0 : loss= 1.5097447633743286  acc= 0.41999998688697815
Batch  1 : loss= 1.471551537513733  acc= 0.6200000047683716
Batch  2 : loss= 1.5112231969833374  acc= 0.46000000834465027
Batch  3 : loss= 1.4252257347106934  acc= 0.6600000262260437
Batch  4 : loss= 1.4869190454483032  acc= 0.46000000834465027
Batch  5 : loss= 1.4429875612258911  acc= 0.5600000023841858
Train: Epoch  12 : loss= 1.4746086398760478  acc= 0.5300000061591467
Batch  0 : loss= 1.5653526782989502  acc= 0.25999999046325684
Batch  1 : loss= 1.585628867149353  acc= 0.25999999046325684
Batch  2 : loss= 1.5762512683868408  acc= 0.3199999928474426
Batch  3 : loss= 1.5692760944366455  acc= 0.36000001430511475
Batch  4 : loss= 1.5505506992340088  acc= 0.3400000035762787
Batch  5 : loss= 1.5219542980194092  acc= 0.3799999952316284
Batch  6 : loss= 1.5634613037109375  acc= 0.3799999952316284
Batch  7 : loss= 1.5582380294799805  acc= 0.3400000035762787
Test: Epoch  12 : loss= 1.5613391548395157  acc= 0.32999999821186066
Batch  0 : loss= 2.5282516479492188
Batch  1 : loss= 2.4388206005096436
Batch  2 : loss= 2.334791898727417
Batch  3 : loss= 2.458311080932617
Batch  4 : loss= 2.435194969177246
Batch  5 : loss= 2.3154726028442383
Train: Epoch  13 : loss= 2.418473800023397
Batch  0 : loss= 1.4680935144424438  acc= 0.5400000214576721
Batch  1 : loss= 1.466225028038025  acc= 0.47999998927116394
Batch  2 : loss= 1.4353221654891968  acc= 0.6800000071525574
Batch  3 : loss= 1.4456944465637207  acc= 0.6200000047683716
Batch  4 : loss= 1.527713656425476  acc= 0.3799999952316284
Batch  5 : loss= 1.4449942111968994  acc= 0.6000000238418579
Train: Epoch  13 : loss= 1.4646738370259602  acc= 0.5500000069538752
Batch  0 : loss= 1.600230097770691  acc= 0.23999999463558197
Batch  1 : loss= 1.588303565979004  acc= 0.2800000011920929
Batch  2 : loss= 1.542311668395996  acc= 0.36000001430511475
Batch  3 : loss= 1.5492674112319946  acc= 0.41999998688697815
Batch  4 : loss= 1.5402570962905884  acc= 0.3199999928474426
Batch  5 : loss= 1.571709156036377  acc= 0.2199999988079071
Batch  6 : loss= 1.5723549127578735  acc= 0.23999999463558197
Batch  7 : loss= 1.5388978719711304  acc= 0.3400000035762787
Test: Epoch  13 : loss= 1.5629164725542068  acc= 0.30249999836087227
Batch  0 : loss= 2.495022773742676
Batch  1 : loss= 2.4249727725982666
Batch  2 : loss= 2.4899630546569824
Batch  3 : loss= 2.4278688430786133
Batch  4 : loss= 2.3985483646392822
Train: Epoch  14 : loss= 2.447275161743164
Batch  0 : loss= 1.4335016012191772  acc= 0.6200000047683716
Batch  1 : loss= 1.4848159551620483  acc= 0.5799999833106995
Batch  2 : loss= 1.4832491874694824  acc= 0.47999998927116394
Batch  3 : loss= 1.4248876571655273  acc= 0.5600000023841858
Batch  4 : loss= 1.4688218832015991  acc= 0.5600000023841858
Batch  5 : loss= 1.4585679769515991  acc= 0.5600000023841858
Batch  6 : loss= 1.4389359951019287  acc= 0.6399999856948853
Train: Epoch  14 : loss= 1.4561114651816232  acc= 0.5714285671710968
Batch  0 : loss= 1.5385239124298096  acc= 0.3199999928474426
Batch  1 : loss= 1.5423190593719482  acc= 0.4000000059604645
Batch  2 : loss= 1.550472617149353  acc= 0.36000001430511475
Batch  3 : loss= 1.5679774284362793  acc= 0.36000001430511475
Batch  4 : loss= 1.5844868421554565  acc= 0.2199999988079071
Batch  5 : loss= 1.6138856410980225  acc= 0.25999999046325684
Batch  6 : loss= 1.548783779144287  acc= 0.3799999952316284
Batch  7 : loss= 1.5980972051620483  acc= 0.3199999928474426
Test: Epoch  14 : loss= 1.5680683106184006  acc= 0.32750000059604645
Batch  0 : loss= 2.3618550300598145
Batch  1 : loss= 2.5111303329467773
Batch  2 : loss= 2.499833106994629
Batch  3 : loss= 2.43045711517334
Train: Epoch  15 : loss= 2.45081889629364
Batch  0 : loss= 1.4794964790344238  acc= 0.46000000834465027
Batch  1 : loss= 1.4577128887176514  acc= 0.6000000238418579
Batch  2 : loss= 1.347989797592163  acc= 0.7799999713897705
Batch  3 : loss= 1.409103512763977  acc= 0.699999988079071
Batch  4 : loss= 1.4971257448196411  acc= 0.5
Batch  5 : loss= 1.4586024284362793  acc= 0.5400000214576721
Batch  6 : loss= 1.4112772941589355  acc= 0.6200000047683716
Train: Epoch  15 : loss= 1.4373297350747245  acc= 0.6000000025544848
Batch  0 : loss= 1.5303534269332886  acc= 0.30000001192092896
Batch  1 : loss= 1.506299614906311  acc= 0.41999998688697815
Batch  2 : loss= 1.5421148538589478  acc= 0.36000001430511475
Batch  3 : loss= 1.5163216590881348  acc= 0.41999998688697815
Batch  4 : loss= 1.546074628829956  acc= 0.41999998688697815
Batch  5 : loss= 1.5738251209259033  acc= 0.25999999046325684
Batch  6 : loss= 1.5332173109054565  acc= 0.4000000059604645
Batch  7 : loss= 1.5683674812316895  acc= 0.3400000035762787
Test: Epoch  15 : loss= 1.539571762084961  acc= 0.36499999836087227
Batch  0 : loss= 2.5808138847351074
Batch  1 : loss= 2.408217430114746
Batch  2 : loss= 2.524635076522827
Train: Epoch  16 : loss= 2.5045554637908936
Batch  0 : loss= 1.4508126974105835  acc= 0.47999998927116394
Batch  1 : loss= 1.3808163404464722  acc= 0.7400000095367432
Batch  2 : loss= 1.4280656576156616  acc= 0.5400000214576721
Batch  3 : loss= 1.3778272867202759  acc= 0.6399999856948853
Batch  4 : loss= 1.4580994844436646  acc= 0.5799999833106995
Batch  5 : loss= 1.4131808280944824  acc= 0.6000000238418579
Batch  6 : loss= 1.4416618347167969  acc= 0.5400000214576721
Train: Epoch  16 : loss= 1.4214948756354195  acc= 0.5885714335100991
Batch  0 : loss= 1.5484775304794312  acc= 0.30000001192092896
Batch  1 : loss= 1.5224356651306152  acc= 0.4399999976158142
Batch  2 : loss= 1.5328702926635742  acc= 0.3199999928474426
Batch  3 : loss= 1.577079176902771  acc= 0.30000001192092896
Batch  4 : loss= 1.5512064695358276  acc= 0.2800000011920929
Batch  5 : loss= 1.567976713180542  acc= 0.3199999928474426
Batch  6 : loss= 1.5764044523239136  acc= 0.30000001192092896
Batch  7 : loss= 1.5741374492645264  acc= 0.3199999928474426
Test: Epoch  16 : loss= 1.5563234686851501  acc= 0.32250000163912773
Batch  0 : loss= 2.6092286109924316
Batch  1 : loss= 2.700845718383789
Train: Epoch  17 : loss= 2.6550371646881104
Batch  0 : loss= 1.3822053670883179  acc= 0.800000011920929
Batch  1 : loss= 1.4395034313201904  acc= 0.5199999809265137
Batch  2 : loss= 1.3446247577667236  acc= 0.7200000286102295
Batch  3 : loss= 1.4150422811508179  acc= 0.5600000023841858
Batch  4 : loss= 1.3290684223175049  acc= 0.7400000095367432
Batch  5 : loss= 1.4781337976455688  acc= 0.5600000023841858
Batch  6 : loss= 1.3775088787078857  acc= 0.7400000095367432
Train: Epoch  17 : loss= 1.3951552765710014  acc= 0.6628571493285043
Batch  0 : loss= 1.5078016519546509  acc= 0.36000001430511475
Batch  1 : loss= 1.5548505783081055  acc= 0.30000001192092896
Batch  2 : loss= 1.531385064125061  acc= 0.3799999952316284
Batch  3 : loss= 1.4894707202911377  acc= 0.5
Batch  4 : loss= 1.5363173484802246  acc= 0.3199999928474426
Batch  5 : loss= 1.5523409843444824  acc= 0.3400000035762787
Batch  6 : loss= 1.5378245115280151  acc= 0.4000000059604645
Batch  7 : loss= 1.5552573204040527  acc= 0.3400000035762787
Test: Epoch  17 : loss= 1.5331560224294662  acc= 0.3675000034272671
Batch  0 : loss= 2.643573522567749
Train: Epoch  18 : loss= 2.643573522567749
Batch  0 : loss= 1.4638499021530151  acc= 0.5799999833106995
Batch  1 : loss= 1.3301185369491577  acc= 0.7200000286102295
Batch  2 : loss= 1.339921474456787  acc= 0.7200000286102295
Batch  3 : loss= 1.390690803527832  acc= 0.6200000047683716
Batch  4 : loss= 1.4330658912658691  acc= 0.6200000047683716
Batch  5 : loss= 1.3825995922088623  acc= 0.6800000071525574
Batch  6 : loss= 1.3701319694519043  acc= 0.699999988079071
Train: Epoch  18 : loss= 1.3871968814304896  acc= 0.6628571493285043
Batch  0 : loss= 1.5205799341201782  acc= 0.4399999976158142
Batch  1 : loss= 1.5208200216293335  acc= 0.4399999976158142
Batch  2 : loss= 1.5249541997909546  acc= 0.36000001430511475
Batch  3 : loss= 1.523316502571106  acc= 0.36000001430511475
Batch  4 : loss= 1.4751100540161133  acc= 0.41999998688697815
Batch  5 : loss= 1.5514934062957764  acc= 0.3400000035762787
Batch  6 : loss= 1.5204112529754639  acc= 0.3799999952316284
Batch  7 : loss= 1.5512977838516235  acc= 0.36000001430511475
Test: Epoch  18 : loss= 1.5234978944063187  acc= 0.38750000298023224
Batch  0 : loss= 2.8458425998687744
Train: Epoch  19 : loss= 2.8458425998687744
Batch  0 : loss= 1.4436002969741821  acc= 0.6399999856948853
Batch  1 : loss= 1.400048851966858  acc= 0.6000000238418579
Batch  2 : loss= 1.331045389175415  acc= 0.7200000286102295
Batch  3 : loss= 1.3840793371200562  acc= 0.6200000047683716
Batch  4 : loss= 1.3530277013778687  acc= 0.6600000262260437
Batch  5 : loss= 1.4406684637069702  acc= 0.5400000214576721
Batch  6 : loss= 1.37663996219635  acc= 0.6800000071525574
Train: Epoch  19 : loss= 1.3898728575025285  acc= 0.6371428711073739
Batch  0 : loss= 1.532902479171753  acc= 0.3199999928474426
Batch  1 : loss= 1.5171796083450317  acc= 0.36000001430511475
Batch  2 : loss= 1.5377533435821533  acc= 0.36000001430511475
Batch  3 : loss= 1.4988458156585693  acc= 0.41999998688697815
Batch  4 : loss= 1.5083568096160889  acc= 0.41999998688697815
Batch  5 : loss= 1.5107922554016113  acc= 0.4000000059604645
Batch  6 : loss= 1.5209721326828003  acc= 0.41999998688697815
Batch  7 : loss= 1.5187268257141113  acc= 0.4000000059604645
Test: Epoch  19 : loss= 1.518191158771515  acc= 0.38749999925494194
Batch  0 : loss= 2.953105926513672
Train: Epoch  20 : loss= 2.953105926513672
Batch  0 : loss= 1.385442852973938  acc= 0.6600000262260437
Batch  1 : loss= 1.4096919298171997  acc= 0.6200000047683716
Batch  2 : loss= 1.3382253646850586  acc= 0.7200000286102295
Batch  3 : loss= 1.3652551174163818  acc= 0.5600000023841858
Batch  4 : loss= 1.3765835762023926  acc= 0.699999988079071
Batch  5 : loss= 1.3871967792510986  acc= 0.6000000238418579
Batch  6 : loss= 1.4191498756408691  acc= 0.5
Train: Epoch  20 : loss= 1.383077927998134  acc= 0.6228571534156799
Batch  0 : loss= 1.5480903387069702  acc= 0.3400000035762787
Batch  1 : loss= 1.5771162509918213  acc= 0.23999999463558197
Batch  2 : loss= 1.4895355701446533  acc= 0.5
Batch  3 : loss= 1.5106377601623535  acc= 0.3799999952316284
Batch  4 : loss= 1.4945423603057861  acc= 0.41999998688697815
Batch  5 : loss= 1.5293408632278442  acc= 0.3799999952316284
Batch  6 : loss= 1.525915503501892  acc= 0.41999998688697815
Batch  7 : loss= 1.5673110485076904  acc= 0.2800000011920929
Test: Epoch  20 : loss= 1.5303112119436264  acc= 0.36999999545514584
Batch  0 : loss= 3.1364288330078125
Train: Epoch  21 : loss= 3.1364288330078125
Batch  0 : loss= 1.379209041595459  acc= 0.6600000262260437
Batch  1 : loss= 1.4010883569717407  acc= 0.5799999833106995
Batch  2 : loss= 1.3487122058868408  acc= 0.6600000262260437
Batch  3 : loss= 1.3886456489562988  acc= 0.7200000286102295
Batch  4 : loss= 1.42995285987854  acc= 0.5799999833106995
Batch  5 : loss= 1.3217697143554688  acc= 0.6800000071525574
Batch  6 : loss= 1.3639928102493286  acc= 0.7200000286102295
Train: Epoch  21 : loss= 1.3761958054133825  acc= 0.657142869063786
Batch  0 : loss= 1.5449353456497192  acc= 0.3400000035762787
Batch  1 : loss= 1.5087780952453613  acc= 0.4000000059604645
Batch  2 : loss= 1.5344966650009155  acc= 0.3799999952316284
Batch  3 : loss= 1.517824411392212  acc= 0.4399999976158142
Batch  4 : loss= 1.573266625404358  acc= 0.3400000035762787
Batch  5 : loss= 1.5861520767211914  acc= 0.25999999046325684
Batch  6 : loss= 1.5344144105911255  acc= 0.41999998688697815
Batch  7 : loss= 1.55500066280365  acc= 0.30000001192092896
Test: Epoch  21 : loss= 1.5443585366010666  acc= 0.35999999940395355
Batch  0 : loss= 3.2160630226135254
Train: Epoch  22 : loss= 3.2160630226135254
Batch  0 : loss= 1.264755368232727  acc= 0.8399999737739563
Batch  1 : loss= 1.3922581672668457  acc= 0.699999988079071
Batch  2 : loss= 1.348007082939148  acc= 0.6399999856948853
Batch  3 : loss= 1.3767362833023071  acc= 0.6600000262260437
Batch  4 : loss= 1.3608988523483276  acc= 0.6399999856948853
Batch  5 : loss= 1.3167366981506348  acc= 0.699999988079071
Batch  6 : loss= 1.3183430433273315  acc= 0.7400000095367432
Train: Epoch  22 : loss= 1.3396764993667603  acc= 0.7028571367263794
Batch  0 : loss= 1.5575227737426758  acc= 0.2800000011920929
Batch  1 : loss= 1.5040374994277954  acc= 0.4000000059604645
Batch  2 : loss= 1.5436509847640991  acc= 0.41999998688697815
Batch  3 : loss= 1.5391404628753662  acc= 0.4000000059604645
Batch  4 : loss= 1.5486044883728027  acc= 0.30000001192092896
Batch  5 : loss= 1.5229027271270752  acc= 0.4000000059604645
Batch  6 : loss= 1.522715449333191  acc= 0.3199999928474426
Batch  7 : loss= 1.5523685216903687  acc= 0.30000001192092896
Test: Epoch  22 : loss= 1.5363678634166718  acc= 0.3525000028312206
Batch  0 : loss= 3.223511219024658
Train: Epoch  23 : loss= 3.223511219024658
Batch  0 : loss= 1.4231109619140625  acc= 0.5799999833106995
Batch  1 : loss= 1.312142014503479  acc= 0.6800000071525574
Batch  2 : loss= 1.3252278566360474  acc= 0.7200000286102295
Batch  3 : loss= 1.3404589891433716  acc= 0.699999988079071
Batch  4 : loss= 1.3319010734558105  acc= 0.6800000071525574
Batch  5 : loss= 1.3474574089050293  acc= 0.6800000071525574
Batch  6 : loss= 1.3527836799621582  acc= 0.6200000047683716
Train: Epoch  23 : loss= 1.3475831406457084  acc= 0.6657142894608634
Batch  0 : loss= 1.5473911762237549  acc= 0.41999998688697815
Batch  1 : loss= 1.5274481773376465  acc= 0.3400000035762787
Batch  2 : loss= 1.5420459508895874  acc= 0.3799999952316284
Batch  3 : loss= 1.5312145948410034  acc= 0.3799999952316284
Batch  4 : loss= 1.5398766994476318  acc= 0.3400000035762787
Batch  5 : loss= 1.5299874544143677  acc= 0.30000001192092896
Batch  6 : loss= 1.57615327835083  acc= 0.25999999046325684
Batch  7 : loss= 1.5299925804138184  acc= 0.36000001430511475
Test: Epoch  23 : loss= 1.54051373898983  acc= 0.3475000001490116
Batch  0 : loss= 3.404536008834839
Train: Epoch  24 : loss= 3.404536008834839
Batch  0 : loss= 1.3527683019638062  acc= 0.6399999856948853
Batch  1 : loss= 1.2847119569778442  acc= 0.7400000095367432
Batch  2 : loss= 1.3197747468948364  acc= 0.7400000095367432
Batch  3 : loss= 1.3448858261108398  acc= 0.6399999856948853
Batch  4 : loss= 1.3594679832458496  acc= 0.6800000071525574
Batch  5 : loss= 1.279817819595337  acc= 0.800000011920929
Batch  6 : loss= 1.3378486633300781  acc= 0.6600000262260437
Train: Epoch  24 : loss= 1.3256107568740845  acc= 0.7000000051089695
Batch  0 : loss= 1.5326776504516602  acc= 0.4000000059604645
Batch  1 : loss= 1.4898475408554077  acc= 0.4399999976158142
Batch  2 : loss= 1.5345256328582764  acc= 0.47999998927116394
Batch  3 : loss= 1.4652177095413208  acc= 0.5
Batch  4 : loss= 1.502219796180725  acc= 0.3799999952316284
Batch  5 : loss= 1.5437594652175903  acc= 0.36000001430511475
Batch  6 : loss= 1.483069658279419  acc= 0.4000000059604645
Batch  7 : loss= 1.4454638957977295  acc= 0.5199999809265137
Test: Epoch  24 : loss= 1.4995976686477661  acc= 0.4349999986588955
Batch  0 : loss= 3.5454061031341553
Train: Epoch  25 : loss= 3.5454061031341553
Batch  0 : loss= 1.3402198553085327  acc= 0.699999988079071
Batch  1 : loss= 1.3280383348464966  acc= 0.7799999713897705
Batch  2 : loss= 1.351966381072998  acc= 0.6800000071525574
Batch  3 : loss= 1.327602744102478  acc= 0.7200000286102295
Batch  4 : loss= 1.3384826183319092  acc= 0.699999988079071
Batch  5 : loss= 1.3203787803649902  acc= 0.6600000262260437
Batch  6 : loss= 1.3054490089416504  acc= 0.7799999713897705
Train: Epoch  25 : loss= 1.3303053889955794  acc= 0.7171428544180733
Batch  0 : loss= 1.5075684785842896  acc= 0.4399999976158142
Batch  1 : loss= 1.5074964761734009  acc= 0.46000000834465027
Batch  2 : loss= 1.5287877321243286  acc= 0.30000001192092896
Batch  3 : loss= 1.5024032592773438  acc= 0.4000000059604645
Batch  4 : loss= 1.5133782625198364  acc= 0.3799999952316284
Batch  5 : loss= 1.5203722715377808  acc= 0.3799999952316284
Batch  6 : loss= 1.4769915342330933  acc= 0.5199999809265137
Batch  7 : loss= 1.5072195529937744  acc= 0.4399999976158142
Test: Epoch  25 : loss= 1.508027195930481  acc= 0.41499999910593033
Batch  0 : loss= 3.4394259452819824
Train: Epoch  26 : loss= 3.4394259452819824
Batch  0 : loss= 1.3355765342712402  acc= 0.6000000238418579
Batch  1 : loss= 1.3207489252090454  acc= 0.6200000047683716
Batch  2 : loss= 1.3054368495941162  acc= 0.7599999904632568
Batch  3 : loss= 1.261001706123352  acc= 0.8199999928474426
Batch  4 : loss= 1.2604920864105225  acc= 0.800000011920929
Batch  5 : loss= 1.3085438013076782  acc= 0.7799999713897705
Batch  6 : loss= 1.291211724281311  acc= 0.800000011920929
Train: Epoch  26 : loss= 1.2975730895996094  acc= 0.7400000010217939
Batch  0 : loss= 1.5609793663024902  acc= 0.41999998688697815
Batch  1 : loss= 1.4985278844833374  acc= 0.4399999976158142
Batch  2 : loss= 1.5042020082473755  acc= 0.41999998688697815
Batch  3 : loss= 1.5503910779953003  acc= 0.2800000011920929
Batch  4 : loss= 1.4727624654769897  acc= 0.5600000023841858
Batch  5 : loss= 1.4920077323913574  acc= 0.4000000059604645
Batch  6 : loss= 1.4817907810211182  acc= 0.41999998688697815
Batch  7 : loss= 1.5235882997512817  acc= 0.4399999976158142
Test: Epoch  26 : loss= 1.5105312019586563  acc= 0.42249999567866325
Batch  0 : loss= 3.636225461959839
Train: Epoch  27 : loss= 3.636225461959839
Batch  0 : loss= 1.2736432552337646  acc= 0.8399999737739563
Batch  1 : loss= 1.3561644554138184  acc= 0.7400000095367432
Batch  2 : loss= 1.3413439989089966  acc= 0.6600000262260437
Batch  3 : loss= 1.3887149095535278  acc= 0.5600000023841858
Batch  4 : loss= 1.2606611251831055  acc= 0.8399999737739563
Batch  5 : loss= 1.354224681854248  acc= 0.6600000262260437
Batch  6 : loss= 1.315752387046814  acc= 0.7599999904632568
Train: Epoch  27 : loss= 1.327214973313468  acc= 0.7228571431977409
Batch  0 : loss= 1.5418034791946411  acc= 0.3799999952316284
Batch  1 : loss= 1.4657220840454102  acc= 0.3799999952316284
Batch  2 : loss= 1.5497207641601562  acc= 0.36000001430511475
Batch  3 : loss= 1.5016015768051147  acc= 0.4000000059604645
Batch  4 : loss= 1.4613332748413086  acc= 0.46000000834465027
Batch  5 : loss= 1.4232254028320312  acc= 0.5400000214576721
Batch  6 : loss= 1.4664726257324219  acc= 0.5
Batch  7 : loss= 1.543495774269104  acc= 0.36000001430511475
Test: Epoch  27 : loss= 1.4941718727350235  acc= 0.42250000685453415
Batch  0 : loss= 3.644927501678467
Train: Epoch  28 : loss= 3.644927501678467
Batch  0 : loss= 1.2946062088012695  acc= 0.7400000095367432
Batch  1 : loss= 1.3134472370147705  acc= 0.7400000095367432
Batch  2 : loss= 1.3623149394989014  acc= 0.6800000071525574
Batch  3 : loss= 1.3090444803237915  acc= 0.7400000095367432
Batch  4 : loss= 1.368537425994873  acc= 0.5799999833106995
Batch  5 : loss= 1.3595614433288574  acc= 0.6600000262260437
Batch  6 : loss= 1.2863558530807495  acc= 0.8199999928474426
Train: Epoch  28 : loss= 1.327695369720459  acc= 0.7085714340209961
Batch  0 : loss= 1.4944037199020386  acc= 0.4399999976158142
Batch  1 : loss= 1.5115814208984375  acc= 0.4399999976158142
Batch  2 : loss= 1.4546258449554443  acc= 0.47999998927116394
Batch  3 : loss= 1.5141525268554688  acc= 0.41999998688697815
Batch  4 : loss= 1.4410496950149536  acc= 0.5400000214576721
Batch  5 : loss= 1.5062315464019775  acc= 0.3799999952316284
Batch  6 : loss= 1.495081901550293  acc= 0.47999998927116394
Batch  7 : loss= 1.4549537897109985  acc= 0.47999998927116394
Test: Epoch  28 : loss= 1.4840100556612015  acc= 0.45749999582767487
Batch  0 : loss= 3.5947213172912598
Train: Epoch  29 : loss= 3.5947213172912598
Batch  0 : loss= 1.2845040559768677  acc= 0.7400000095367432
Batch  1 : loss= 1.275383472442627  acc= 0.7599999904632568
Batch  2 : loss= 1.3432343006134033  acc= 0.7200000286102295
Batch  3 : loss= 1.286954402923584  acc= 0.8399999737739563
Batch  4 : loss= 1.3167312145233154  acc= 0.7200000286102295
Batch  5 : loss= 1.2183794975280762  acc= 0.800000011920929
Batch  6 : loss= 1.2515002489089966  acc= 0.800000011920929
Train: Epoch  29 : loss= 1.28238388470241  acc= 0.7685714364051819
Batch  0 : loss= 1.4491875171661377  acc= 0.5199999809265137
Batch  1 : loss= 1.4856219291687012  acc= 0.46000000834465027
Batch  2 : loss= 1.512418270111084  acc= 0.4000000059604645
Batch  3 : loss= 1.5485293865203857  acc= 0.2800000011920929
Batch  4 : loss= 1.4979177713394165  acc= 0.3799999952316284
Batch  5 : loss= 1.4967315196990967  acc= 0.4399999976158142
Batch  6 : loss= 1.5235114097595215  acc= 0.41999998688697815
Batch  7 : loss= 1.4485788345336914  acc= 0.5799999833106995
Test: Epoch  29 : loss= 1.4953120797872543  acc= 0.4349999949336052
Batch  0 : loss= 3.7950193881988525
Train: Epoch  30 : loss= 3.7950193881988525
Batch  0 : loss= 1.2457581758499146  acc= 0.8399999737739563
Batch  1 : loss= 1.2291343212127686  acc= 0.8199999928474426
Batch  2 : loss= 1.263368844985962  acc= 0.7799999713897705
Batch  3 : loss= 1.340591549873352  acc= 0.7200000286102295
Batch  4 : loss= 1.2982690334320068  acc= 0.7200000286102295
Batch  5 : loss= 1.3008544445037842  acc= 0.7200000286102295
Batch  6 : loss= 1.3096851110458374  acc= 0.699999988079071
Train: Epoch  30 : loss= 1.2839516401290894  acc= 0.757142858845847
Batch  0 : loss= 1.4725151062011719  acc= 0.4399999976158142
Batch  1 : loss= 1.5107946395874023  acc= 0.3799999952316284
Batch  2 : loss= 1.463840126991272  acc= 0.5199999809265137
Batch  3 : loss= 1.4965312480926514  acc= 0.41999998688697815
Batch  4 : loss= 1.5029391050338745  acc= 0.4000000059604645
Batch  5 : loss= 1.5328384637832642  acc= 0.36000001430511475
Batch  6 : loss= 1.519374132156372  acc= 0.3799999952316284
Batch  7 : loss= 1.5177754163742065  acc= 0.3799999952316284
Test: Epoch  30 : loss= 1.5020760297775269  acc= 0.4099999964237213
Batch  0 : loss= 3.907430648803711
Train: Epoch  31 : loss= 3.907430648803711
Batch  0 : loss= 1.263230800628662  acc= 0.6800000071525574
Batch  1 : loss= 1.2631148099899292  acc= 0.8600000143051147
Batch  2 : loss= 1.2665525674819946  acc= 0.7400000095367432
Batch  3 : loss= 1.2891802787780762  acc= 0.8199999928474426
Batch  4 : loss= 1.311724066734314  acc= 0.6600000262260437
Batch  5 : loss= 1.3249531984329224  acc= 0.6600000262260437
Batch  6 : loss= 1.3032689094543457  acc= 0.699999988079071
Train: Epoch  31 : loss= 1.288860661642892  acc= 0.7314285806247166
Batch  0 : loss= 1.5187379121780396  acc= 0.41999998688697815
Batch  1 : loss= 1.5354931354522705  acc= 0.4000000059604645
Batch  2 : loss= 1.5035406351089478  acc= 0.46000000834465027
Batch  3 : loss= 1.4995445013046265  acc= 0.36000001430511475
Batch  4 : loss= 1.5538969039916992  acc= 0.3199999928474426
Batch  5 : loss= 1.5312196016311646  acc= 0.3199999928474426
Batch  6 : loss= 1.5002037286758423  acc= 0.3799999952316284
Batch  7 : loss= 1.5112884044647217  acc= 0.41999998688697815
Test: Epoch  31 : loss= 1.519240602850914  acc= 0.38499999791383743
Batch  0 : loss= 3.7671964168548584
Train: Epoch  32 : loss= 3.7671964168548584
Batch  0 : loss= 1.2496652603149414  acc= 0.8199999928474426
Batch  1 : loss= 1.2489932775497437  acc= 0.7799999713897705
Batch  2 : loss= 1.2769912481307983  acc= 0.6800000071525574
Batch  3 : loss= 1.2529191970825195  acc= 0.8199999928474426
Batch  4 : loss= 1.267877459526062  acc= 0.7799999713897705
Batch  5 : loss= 1.2664142847061157  acc= 0.7400000095367432
Batch  6 : loss= 1.207132339477539  acc= 0.8799999952316284
Train: Epoch  32 : loss= 1.2528561523982458  acc= 0.7857142771993365
Batch  0 : loss= 1.4797909259796143  acc= 0.4000000059604645
Batch  1 : loss= 1.4776611328125  acc= 0.47999998927116394
Batch  2 : loss= 1.5140800476074219  acc= 0.36000001430511475
Batch  3 : loss= 1.488777756690979  acc= 0.47999998927116394
Batch  4 : loss= 1.4939366579055786  acc= 0.47999998927116394
Batch  5 : loss= 1.4697602987289429  acc= 0.47999998927116394
Batch  6 : loss= 1.527974247932434  acc= 0.41999998688697815
Batch  7 : loss= 1.488560438156128  acc= 0.4399999976158142
Test: Epoch  32 : loss= 1.4925676882266998  acc= 0.4424999952316284
Batch  0 : loss= 3.886596441268921
Train: Epoch  33 : loss= 3.886596441268921
Batch  0 : loss= 1.2823959589004517  acc= 0.7599999904632568
Batch  1 : loss= 1.3024216890335083  acc= 0.7799999713897705
Batch  2 : loss= 1.2321721315383911  acc= 0.8799999952316284
Batch  3 : loss= 1.2795337438583374  acc= 0.7599999904632568
Batch  4 : loss= 1.3088157176971436  acc= 0.7599999904632568
Batch  5 : loss= 1.2809724807739258  acc= 0.7400000095367432
Batch  6 : loss= 1.2762507200241089  acc= 0.8399999737739563
Train: Epoch  33 : loss= 1.280366063117981  acc= 0.7885714173316956
Batch  0 : loss= 1.5363894701004028  acc= 0.3799999952316284
Batch  1 : loss= 1.4970358610153198  acc= 0.5
Batch  2 : loss= 1.4555624723434448  acc= 0.47999998927116394
Batch  3 : loss= 1.5070363283157349  acc= 0.3799999952316284
Batch  4 : loss= 1.442305326461792  acc= 0.5600000023841858
Batch  5 : loss= 1.5443440675735474  acc= 0.3400000035762787
Batch  6 : loss= 1.530775547027588  acc= 0.3400000035762787
Batch  7 : loss= 1.5463593006134033  acc= 0.2800000011920929
Test: Epoch  33 : loss= 1.5074760466814041  acc= 0.4074999988079071
Batch  0 : loss= 3.78359055519104
Train: Epoch  34 : loss= 3.78359055519104
Batch  0 : loss= 1.2602944374084473  acc= 0.8199999928474426
Batch  1 : loss= 1.3109025955200195  acc= 0.699999988079071
Batch  2 : loss= 1.201509952545166  acc= 0.9200000166893005
Batch  3 : loss= 1.3190730810165405  acc= 0.7200000286102295
Batch  4 : loss= 1.2283577919006348  acc= 0.8399999737739563
Batch  5 : loss= 1.2570521831512451  acc= 0.7599999904632568
Batch  6 : loss= 1.2403455972671509  acc= 0.8600000143051147
Train: Epoch  34 : loss= 1.2596479484013148  acc= 0.8028571435383388
Batch  0 : loss= 1.5347927808761597  acc= 0.30000001192092896
Batch  1 : loss= 1.508265733718872  acc= 0.36000001430511475
Batch  2 : loss= 1.5572367906570435  acc= 0.3199999928474426
Batch  3 : loss= 1.4350122213363647  acc= 0.5400000214576721
Batch  4 : loss= 1.5105023384094238  acc= 0.4399999976158142
Batch  5 : loss= 1.5161839723587036  acc= 0.5
Batch  6 : loss= 1.539646863937378  acc= 0.36000001430511475
Batch  7 : loss= 1.4683778285980225  acc= 0.47999998927116394
Test: Epoch  34 : loss= 1.508752316236496  acc= 0.4125000052154064
Batch  0 : loss= 3.8267951011657715
Train: Epoch  35 : loss= 3.8267951011657715
Batch  0 : loss= 1.2726993560791016  acc= 0.7799999713897705
Batch  1 : loss= 1.259911298751831  acc= 0.7599999904632568
Batch  2 : loss= 1.2518748044967651  acc= 0.8399999737739563
Batch  3 : loss= 1.2210664749145508  acc= 0.8399999737739563
Batch  4 : loss= 1.2877432107925415  acc= 0.7599999904632568
Batch  5 : loss= 1.2754958868026733  acc= 0.800000011920929
Batch  6 : loss= 1.2577961683273315  acc= 0.7599999904632568
Train: Epoch  35 : loss= 1.2609410285949707  acc= 0.7914285574640546
Batch  0 : loss= 1.506110429763794  acc= 0.4000000059604645
Batch  1 : loss= 1.438392162322998  acc= 0.4399999976158142
Batch  2 : loss= 1.4944316148757935  acc= 0.41999998688697815
Batch  3 : loss= 1.529817819595337  acc= 0.4000000059604645
Batch  4 : loss= 1.4750289916992188  acc= 0.47999998927116394
Batch  5 : loss= 1.494696021080017  acc= 0.4000000059604645
Batch  6 : loss= 1.5513173341751099  acc= 0.2800000011920929
Batch  7 : loss= 1.4838240146636963  acc= 0.46000000834465027
Test: Epoch  35 : loss= 1.4967022985219955  acc= 0.4100000001490116
Batch  0 : loss= 3.8892855644226074
Train: Epoch  36 : loss= 3.8892855644226074
Batch  0 : loss= 1.2599891424179077  acc= 0.800000011920929
Batch  1 : loss= 1.2710208892822266  acc= 0.7599999904632568
Batch  2 : loss= 1.2764784097671509  acc= 0.7799999713897705
Batch  3 : loss= 1.2405943870544434  acc= 0.699999988079071
Batch  4 : loss= 1.2309410572052002  acc= 0.7799999713897705
Batch  5 : loss= 1.2243109941482544  acc= 0.8799999952316284
Batch  6 : loss= 1.278167963027954  acc= 0.7599999904632568
Train: Epoch  36 : loss= 1.2545004061290197  acc= 0.779999988419669
Batch  0 : loss= 1.4644017219543457  acc= 0.5400000214576721
Batch  1 : loss= 1.5169388055801392  acc= 0.36000001430511475
Batch  2 : loss= 1.5674628019332886  acc= 0.2800000011920929
Batch  3 : loss= 1.504367709159851  acc= 0.41999998688697815
Batch  4 : loss= 1.4962234497070312  acc= 0.5
Batch  5 : loss= 1.516911268234253  acc= 0.4000000059604645
Batch  6 : loss= 1.4839941263198853  acc= 0.5
Batch  7 : loss= 1.4756802320480347  acc= 0.41999998688697815
Test: Epoch  36 : loss= 1.5032475143671036  acc= 0.42750000208616257
Batch  0 : loss= 3.890346050262451
Train: Epoch  37 : loss= 3.890346050262451
Batch  0 : loss= 1.2215899229049683  acc= 0.8799999952316284
Batch  1 : loss= 1.2479408979415894  acc= 0.800000011920929
Batch  2 : loss= 1.3404852151870728  acc= 0.6800000071525574
Batch  3 : loss= 1.2607550621032715  acc= 0.7400000095367432
Batch  4 : loss= 1.2487645149230957  acc= 0.8600000143051147
Batch  5 : loss= 1.2860665321350098  acc= 0.7799999713897705
Batch  6 : loss= 1.2608642578125  acc= 0.800000011920929
Train: Epoch  37 : loss= 1.2666380575725011  acc= 0.7914285744939532
Batch  0 : loss= 1.504729151725769  acc= 0.41999998688697815
Batch  1 : loss= 1.4909754991531372  acc= 0.41999998688697815
Batch  2 : loss= 1.5168206691741943  acc= 0.4399999976158142
Batch  3 : loss= 1.5071700811386108  acc= 0.3400000035762787
Batch  4 : loss= 1.5382298231124878  acc= 0.3799999952316284
Batch  5 : loss= 1.5243110656738281  acc= 0.46000000834465027
Batch  6 : loss= 1.5463616847991943  acc= 0.30000001192092896
Batch  7 : loss= 1.4891663789749146  acc= 0.41999998688697815
Test: Epoch  37 : loss= 1.514720544219017  acc= 0.3974999971687794
Batch  0 : loss= 3.839428186416626
Train: Epoch  38 : loss= 3.839428186416626
Batch  0 : loss= 1.2678403854370117  acc= 0.7400000095367432
Batch  1 : loss= 1.2481127977371216  acc= 0.7799999713897705
Batch  2 : loss= 1.2622342109680176  acc= 0.7400000095367432
Batch  3 : loss= 1.2704873085021973  acc= 0.7200000286102295
Batch  4 : loss= 1.2440720796585083  acc= 0.8399999737739563
Batch  5 : loss= 1.2534927129745483  acc= 0.800000011920929
Batch  6 : loss= 1.2549166679382324  acc= 0.7400000095367432
Train: Epoch  38 : loss= 1.2573080233165197  acc= 0.7657142877578735
Batch  0 : loss= 1.444953203201294  acc= 0.5
Batch  1 : loss= 1.5061739683151245  acc= 0.41999998688697815
Batch  2 : loss= 1.498640537261963  acc= 0.3799999952316284
Batch  3 : loss= 1.4837408065795898  acc= 0.41999998688697815
Batch  4 : loss= 1.5028146505355835  acc= 0.41999998688697815
Batch  5 : loss= 1.4510520696640015  acc= 0.47999998927116394
Batch  6 : loss= 1.4038786888122559  acc= 0.6000000238418579
Batch  7 : loss= 1.4474303722381592  acc= 0.47999998927116394
Test: Epoch  38 : loss= 1.4673355370759964  acc= 0.4624999947845936
Batch  0 : loss= 4.0694899559021
Train: Epoch  39 : loss= 4.0694899559021
Batch  0 : loss= 1.2978928089141846  acc= 0.7200000286102295
Batch  1 : loss= 1.209612250328064  acc= 0.8600000143051147
Batch  2 : loss= 1.191872000694275  acc= 0.8199999928474426
Batch  3 : loss= 1.264683723449707  acc= 0.7200000286102295
Batch  4 : loss= 1.2732194662094116  acc= 0.7599999904632568
Batch  5 : loss= 1.2815288305282593  acc= 0.7200000286102295
Batch  6 : loss= 1.2299442291259766  acc= 0.8199999928474426
Train: Epoch  39 : loss= 1.2498219013214111  acc= 0.7742857251848493
Batch  0 : loss= 1.4930685758590698  acc= 0.46000000834465027
Batch  1 : loss= 1.4912633895874023  acc= 0.46000000834465027
Batch  2 : loss= 1.4734055995941162  acc= 0.5
Batch  3 : loss= 1.5159677267074585  acc= 0.46000000834465027
Batch  4 : loss= 1.4815107583999634  acc= 0.5199999809265137
Batch  5 : loss= 1.510518193244934  acc= 0.47999998927116394
Batch  6 : loss= 1.4561082124710083  acc= 0.4399999976158142
Batch  7 : loss= 1.4411184787750244  acc= 0.5
Test: Epoch  39 : loss= 1.4828701168298721  acc= 0.47749999910593033
Batch  0 : loss= 3.9864840507507324
Train: Epoch  40 : loss= 3.9864840507507324
Batch  0 : loss= 1.2015225887298584  acc= 0.8600000143051147
Batch  1 : loss= 1.2826828956604004  acc= 0.7799999713897705
Batch  2 : loss= 1.2438080310821533  acc= 0.7400000095367432
Batch  3 : loss= 1.2732826471328735  acc= 0.7200000286102295
Batch  4 : loss= 1.1879137754440308  acc= 0.8600000143051147
Batch  5 : loss= 1.2567830085754395  acc= 0.7400000095367432
Batch  6 : loss= 1.2511948347091675  acc= 0.7400000095367432
Train: Epoch  40 : loss= 1.2424553973334176  acc= 0.7771428653172084
Batch  0 : loss= 1.4701910018920898  acc= 0.4000000059604645
Batch  1 : loss= 1.4851874113082886  acc= 0.46000000834465027
Batch  2 : loss= 1.4583265781402588  acc= 0.5600000023841858
Batch  3 : loss= 1.4666800498962402  acc= 0.46000000834465027
Batch  4 : loss= 1.4733796119689941  acc= 0.5199999809265137
Batch  5 : loss= 1.4867335557937622  acc= 0.47999998927116394
Batch  6 : loss= 1.4845854043960571  acc= 0.36000001430511475
Batch  7 : loss= 1.463292121887207  acc= 0.47999998927116394
Test: Epoch  40 : loss= 1.4735469669103622  acc= 0.4649999998509884
Batch  0 : loss= 4.03394889831543
Train: Epoch  41 : loss= 4.03394889831543
Batch  0 : loss= 1.2352871894836426  acc= 0.800000011920929
Batch  1 : loss= 1.2588385343551636  acc= 0.8799999952316284
Batch  2 : loss= 1.2397255897521973  acc= 0.7799999713897705
Batch  3 : loss= 1.2349615097045898  acc= 0.8399999737739563
Batch  4 : loss= 1.2757651805877686  acc= 0.7200000286102295
Batch  5 : loss= 1.2435507774353027  acc= 0.8600000143051147
Batch  6 : loss= 1.2238054275512695  acc= 0.7799999713897705
Train: Epoch  41 : loss= 1.244562029838562  acc= 0.808571423803057
Batch  0 : loss= 1.4632431268692017  acc= 0.46000000834465027
Batch  1 : loss= 1.5153700113296509  acc= 0.4399999976158142
Batch  2 : loss= 1.5102355480194092  acc= 0.41999998688697815
Batch  3 : loss= 1.4404650926589966  acc= 0.5400000214576721
Batch  4 : loss= 1.4317946434020996  acc= 0.5600000023841858
Batch  5 : loss= 1.480456829071045  acc= 0.46000000834465027
Batch  6 : loss= 1.4524542093276978  acc= 0.5
Batch  7 : loss= 1.4708492755889893  acc= 0.4000000059604645
Test: Epoch  41 : loss= 1.4706085920333862  acc= 0.4725000038743019
Batch  0 : loss= 4.16078519821167
Train: Epoch  42 : loss= 4.16078519821167
Batch  0 : loss= 1.2618188858032227  acc= 0.800000011920929
Batch  1 : loss= 1.223238229751587  acc= 0.7799999713897705
Batch  2 : loss= 1.1519436836242676  acc= 0.8999999761581421
Batch  3 : loss= 1.2094286680221558  acc= 0.8399999737739563
Batch  4 : loss= 1.2968558073043823  acc= 0.7799999713897705
Batch  5 : loss= 1.2117539644241333  acc= 0.8600000143051147
Batch  6 : loss= 1.2474514245986938  acc= 0.7799999713897705
Train: Epoch  42 : loss= 1.2289272376469202  acc= 0.8199999843324933
Batch  0 : loss= 1.4597947597503662  acc= 0.47999998927116394
Batch  1 : loss= 1.4613226652145386  acc= 0.5199999809265137
Batch  2 : loss= 1.4707388877868652  acc= 0.41999998688697815
Batch  3 : loss= 1.4858278036117554  acc= 0.3799999952316284
Batch  4 : loss= 1.5194026231765747  acc= 0.36000001430511475
Batch  5 : loss= 1.5020946264266968  acc= 0.3799999952316284
Batch  6 : loss= 1.4865608215332031  acc= 0.46000000834465027
Batch  7 : loss= 1.4683767557144165  acc= 0.5199999809265137
Test: Epoch  42 : loss= 1.481764867901802  acc= 0.4399999938905239
Batch  0 : loss= 3.954441785812378
Train: Epoch  43 : loss= 3.954441785812378
Batch  0 : loss= 1.2634589672088623  acc= 0.7400000095367432
Batch  1 : loss= 1.2874261140823364  acc= 0.7400000095367432
Batch  2 : loss= 1.1952433586120605  acc= 0.8600000143051147
Batch  3 : loss= 1.2314985990524292  acc= 0.8199999928474426
Batch  4 : loss= 1.2409262657165527  acc= 0.8199999928474426
Batch  5 : loss= 1.2158844470977783  acc= 0.8600000143051147
Batch  6 : loss= 1.2792104482650757  acc= 0.7200000286102295
Train: Epoch  43 : loss= 1.2448068857192993  acc= 0.7942857231412616
Batch  0 : loss= 1.4567052125930786  acc= 0.47999998927116394
Batch  1 : loss= 1.4466133117675781  acc= 0.5600000023841858
Batch  2 : loss= 1.5266900062561035  acc= 0.30000001192092896
Batch  3 : loss= 1.5028584003448486  acc= 0.4399999976158142
Batch  4 : loss= 1.4427255392074585  acc= 0.5
Batch  5 : loss= 1.4493608474731445  acc= 0.47999998927116394
Batch  6 : loss= 1.4719847440719604  acc= 0.5
Batch  7 : loss= 1.4912986755371094  acc= 0.46000000834465027
Test: Epoch  43 : loss= 1.4735295921564102  acc= 0.4649999998509884
Batch  0 : loss= 4.0377631187438965
Train: Epoch  44 : loss= 4.0377631187438965
Batch  0 : loss= 1.2243804931640625  acc= 0.8799999952316284
Batch  1 : loss= 1.2342052459716797  acc= 0.7599999904632568
Batch  2 : loss= 1.21858549118042  acc= 0.8399999737739563
Batch  3 : loss= 1.1911362409591675  acc= 0.8600000143051147
Batch  4 : loss= 1.2553654909133911  acc= 0.8199999928474426
Batch  5 : loss= 1.265366554260254  acc= 0.7599999904632568
Batch  6 : loss= 1.239822268486023  acc= 0.800000011920929
Train: Epoch  44 : loss= 1.2326945407049996  acc= 0.8171428527150836
Batch  0 : loss= 1.47696852684021  acc= 0.4399999976158142
Batch  1 : loss= 1.4691531658172607  acc= 0.4399999976158142
Batch  2 : loss= 1.5613963603973389  acc= 0.2800000011920929
Batch  3 : loss= 1.4909814596176147  acc= 0.4000000059604645
Batch  4 : loss= 1.4603056907653809  acc= 0.4399999976158142
Batch  5 : loss= 1.500813603401184  acc= 0.41999998688697815
Batch  6 : loss= 1.424866795539856  acc= 0.5799999833106995
Batch  7 : loss= 1.4669928550720215  acc= 0.4399999976158142
Test: Epoch  44 : loss= 1.4814348071813583  acc= 0.4299999959766865
Batch  0 : loss= 4.171684265136719

